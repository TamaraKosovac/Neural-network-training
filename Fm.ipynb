{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9438b3df",
      "metadata": {
        "id": "9438b3df"
      },
      "outputs": [],
      "source": [
        "import torch as T\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e57d5de5",
      "metadata": {
        "id": "e57d5de5"
      },
      "outputs": [],
      "source": [
        "class CovertypeClass(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(54, 128)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(p=0.2)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(p=0.2)\n",
        "        self.layer3 = nn.Linear(128, 64)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.output = nn.Linear(64, 7)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.layer1(x))\n",
        "        x = self.drop1(x)\n",
        "        x = self.act2(self.layer2(x))\n",
        "        x = self.drop2(x)\n",
        "        x = self.act3(self.layer3(x))\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4fc0af48",
      "metadata": {
        "id": "4fc0af48"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "covtype = fetch_covtype()\n",
        "X = covtype.data\n",
        "y = covtype.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4e7476ed",
      "metadata": {
        "id": "4e7476ed"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c72a51cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c72a51cc",
        "outputId": "aefa31e5-09ce-4b0c-c649-832bf9353b89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7a7933e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a7933e4",
        "outputId": "682af98f-4567-443f-b37a-34aac95a70d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "X_train_t = T.tensor(X_train).float()\n",
        "X_test_t = T.tensor(X_test).float()\n",
        "y_train_t = T.tensor(y_train).long().reshape(-1)\n",
        "y_train_t = y_train_t - 1\n",
        "y_test_t = T.tensor(y_test).long().reshape(-1)\n",
        "y_test_t = y_test_t - 1\n",
        "print(y_train_t.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f2f8fd45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f8fd45",
        "outputId": "c631dcac-d9f4-4266-b73c-91f72371c3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([464809, 54])\n",
            "torch.Size([464809])\n"
          ]
        }
      ],
      "source": [
        "print(X_train_t.shape)\n",
        "print(y_train_t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8b8d19ac",
      "metadata": {
        "id": "8b8d19ac"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "29af4ba7",
      "metadata": {
        "id": "29af4ba7"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ef292cdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef292cdf",
        "outputId": "8be88f28-cb53-4bf0-9500-3157df30baf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = T.device(\"cuda:0\") if T.cuda.is_available() else T.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a7fe6670",
      "metadata": {
        "id": "a7fe6670"
      },
      "outputs": [],
      "source": [
        "net = CovertypeClass().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4efdb451",
      "metadata": {
        "id": "4efdb451"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4f90f2cc",
      "metadata": {
        "id": "4f90f2cc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1d723a66",
      "metadata": {
        "id": "1d723a66"
      },
      "outputs": [],
      "source": [
        "def test_model(net, loss_fn, test_loader):\n",
        "    total_loss = 0\n",
        "    net.eval()\n",
        "\n",
        "    with T.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = net(x)\n",
        "            preds_max = np.argmax(preds, axis = 1)\n",
        "            loss = loss_fn(preds, y)\n",
        "            total_loss += loss.item()\n",
        "            recall = recall_score(y, preds_max, average = 'weighted', zero_division = 0)\n",
        "            precision = precision_score(y, preds_max, average = 'weighted', zero_division = 0)\n",
        "\n",
        "    print(total_loss / len(test_loader))\n",
        "    print(recall)\n",
        "    print(precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0afd4cd5",
      "metadata": {
        "id": "0afd4cd5"
      },
      "outputs": [],
      "source": [
        "optimizer = T.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "18a77516",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a77516",
        "outputId": "271d0ea9-977e-471e-d0f0-b7254f15b231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.129789435390859\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "test_model(net, loss_fn, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4182ee93",
      "metadata": {
        "id": "4182ee93"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "defee97e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defee97e",
        "outputId": "a0fdd178-0f66-48f1-fc6e-12d7421bae54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running epoch: 0\n",
            "Running epoch: 5\n",
            "Running epoch: 10\n",
            "Running epoch: 15\n",
            "Running epoch: 20\n",
            "Running epoch: 25\n",
            "Running epoch: 30\n",
            "Running epoch: 35\n",
            "Running epoch: 40\n",
            "Running epoch: 45\n"
          ]
        }
      ],
      "source": [
        "net.train()\n",
        "for i in range(EPOCHS):\n",
        "    if i % 5 == 0:\n",
        "        print(f\"Running epoch: {i}\")\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        preds = net(x)\n",
        "        loss = loss_fn(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "361b0acd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361b0acd",
        "outputId": "1af7a571-1807-45fb-ba06-df4aa777753f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6798833044418153\n",
            "0.7272727272727273\n",
            "0.5289256198347108\n"
          ]
        }
      ],
      "source": [
        "test_model(net, loss_fn, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "da358a2e",
      "metadata": {
        "id": "da358a2e"
      },
      "outputs": [],
      "source": [
        "best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "tolerance = 0\n",
        "max_tolerance = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_t, y_train_t, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 32)"
      ],
      "metadata": {
        "id": "DRQeQp86GOar"
      },
      "id": "DRQeQp86GOar",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    net.train()\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        preds = net(x)\n",
        "        loss = loss_fn(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            preds_val = net(x_val)\n",
        "            loss_val = loss_fn(preds_val, y_val)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
        "\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        tolerance = 0\n",
        "    else:\n",
        "        tolerance += 1\n",
        "\n",
        "\n",
        "    if tolerance > max_tolerance:\n",
        "        print(f\"Early stopping at epoch {epoch+1}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTOVDA2qYVWi",
        "outputId": "a1c4850d-ec96-4911-aac4-51fe120e9bd0"
      },
      "id": "MTOVDA2qYVWi",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.6916, Val Loss=2.0226\n",
            "Epoch 2: Train Loss=1.6773, Val Loss=1.4511\n",
            "Epoch 3: Train Loss=1.7086, Val Loss=1.6186\n",
            "Epoch 4: Train Loss=1.7680, Val Loss=1.7565\n",
            "Epoch 5: Train Loss=1.6737, Val Loss=1.5940\n",
            "Early stopping at epoch 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [32, 64, 128]\n",
        "size_of_hidden_layers = [64, 128, 256]\n",
        "\n",
        "best_precision = 0.0\n",
        "best_model = None"
      ],
      "metadata": {
        "id": "zrVgjR_La7qT"
      },
      "id": "zrVgjR_La7qT",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "tolerance = 0\n",
        "max_tolerance = 2"
      ],
      "metadata": {
        "id": "Kbj43sqpa-W_"
      },
      "id": "Kbj43sqpa-W_",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "\n",
        "for lr in learning_rate:\n",
        "    for size in size_of_hidden_layers:\n",
        "        for batch_size in batch_sizes:\n",
        "            model = CovertypeClass(54, size, 7)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "            for epoch in range(EPOCHS):\n",
        "                train_loss = 0.0\n",
        "                val_loss = 0.0\n",
        "                net.train()\n",
        "                for x, y in train_loader:\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    preds = net(x)\n",
        "                    loss = loss_fn(preds, y)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss += loss.item()\n",
        "\n",
        "                net.eval()\n",
        "                with torch.no_grad():\n",
        "                    for x_val, y_val in val_loader:\n",
        "                        preds_val = net(x_val)\n",
        "                        loss_val = loss_fn(preds_val, y_val)\n",
        "                        val_loss += loss.item()\n",
        "\n",
        "                precision = precision_score(y_val, torch.argmax(preds_val, dim = 1), average = 'weighted', zero_division = 0)\n",
        "                print(precision)\n",
        "\n",
        "                if precision > best_precision:\n",
        "                    best_precision = precision\n",
        "                    best_model = net\n",
        "                    best_lr = lr\n",
        "                    best_size = size\n",
        "                    best_batch_size = batch_size\n",
        "\n",
        "                train_loss /= len(train_loader)\n",
        "                val_loss /= len(val_loader)\n",
        "\n",
        "                print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
        "\n",
        "                if val_loss < best_loss:\n",
        "                    best_loss = val_loss\n",
        "                    best_epoch = epoch\n",
        "                    tolerance = 0\n",
        "                else:\n",
        "                    tolerance += 1\n",
        "\n",
        "                if tolerance > max_tolerance:\n",
        "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                    best_loss = float('inf')\n",
        "                    best_epoch = 0\n",
        "                    tolerance = 0\n",
        "                    max_tolerance = 2\n",
        "                    break\n",
        "\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Best Model:\", best_model)\n",
        "print(\"Best learning rate:\", best_lr)\n",
        "print(\"Best size of hidden layers:\", best_size)\n",
        "print(\"Best batch size:\", best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-RZ_FQxbCM9",
        "outputId": "4ed7946a-06ef-4619-d6e3-a8a59249b5b1"
      },
      "id": "G-RZ_FQxbCM9",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "Epoch 1: Train Loss=1.6760, Val Loss=1.6231\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.7016\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6760, Val Loss=1.4664\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6757, Val Loss=1.5284\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6760, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6760, Val Loss=1.7277\n",
            "Early stopping at epoch 8\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6762, Val Loss=1.7453\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6758, Val Loss=1.4094\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6762, Val Loss=1.6157\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6760, Val Loss=1.7546\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6758, Val Loss=1.4431\n",
            "Early stopping at epoch 6\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.4511\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6758, Val Loss=2.0226\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6758, Val Loss=1.5835\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6762, Val Loss=1.8731\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6760, Val Loss=1.4511\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6762, Val Loss=1.5795\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.8635\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.4511\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.6211\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.7015\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6762, Val Loss=1.7597\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6762, Val Loss=1.5820\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6759, Val Loss=1.4755\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6761, Val Loss=1.6969\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6761, Val Loss=1.4511\n",
            "0.25\n",
            "Epoch 9: Train Loss=1.6760, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 10: Train Loss=1.6760, Val Loss=1.3340\n",
            "0.25\n",
            "Epoch 11: Train Loss=1.6759, Val Loss=1.5892\n",
            "0.25\n",
            "Epoch 12: Train Loss=1.6759, Val Loss=1.1895\n",
            "0.25\n",
            "Epoch 13: Train Loss=1.6761, Val Loss=1.4409\n",
            "0.25\n",
            "Epoch 14: Train Loss=1.6760, Val Loss=1.7634\n",
            "0.25\n",
            "Epoch 15: Train Loss=1.6759, Val Loss=1.6191\n",
            "Early stopping at epoch 15\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.6456\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.7401\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6761, Val Loss=1.9065\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.5488\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6758, Val Loss=1.8098\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6761, Val Loss=1.9051\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6762, Val Loss=1.8060\n",
            "Early stopping at epoch 8\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=1.7026\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6761, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.6433\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.3600\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6760, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6759, Val Loss=1.4785\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6759, Val Loss=1.5840\n",
            "Early stopping at epoch 7\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.2994\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=2.0226\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.4762\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=2.1654\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.3594\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6758, Val Loss=1.7842\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.7966\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.7652\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6761, Val Loss=1.6147\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.3587\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6758, Val Loss=1.5605\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.7039\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.7369\n",
            "Early stopping at epoch 5\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=1.6212\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.7255\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.7369\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6756, Val Loss=1.4511\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=1.9859\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.7625\n",
            "Early stopping at epoch 5\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6760, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6757, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6762, Val Loss=1.6195\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.5249\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.8102\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6760, Val Loss=1.9064\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6759, Val Loss=1.8797\n",
            "Early stopping at epoch 7\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6762, Val Loss=1.7895\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6761, Val Loss=1.8697\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6762, Val Loss=1.6750\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6757, Val Loss=1.3083\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6759, Val Loss=1.6179\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6758, Val Loss=1.3083\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6759, Val Loss=1.3348\n",
            "Early stopping at epoch 8\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6763, Val Loss=1.8748\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.5891\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.7617\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.4738\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.8797\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6760, Val Loss=1.6051\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6758, Val Loss=1.7013\n",
            "Early stopping at epoch 7\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.6185\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6762, Val Loss=1.7006\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.5793\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.7369\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.8646\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6759, Val Loss=1.7369\n",
            "Early stopping at epoch 6\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.6961\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.5799\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6758, Val Loss=1.4780\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6761, Val Loss=1.4776\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.8095\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6761, Val Loss=1.4780\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6758, Val Loss=1.5024\n",
            "Early stopping at epoch 7\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=2.0129\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6758, Val Loss=1.4085\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.8695\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=1.7302\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.5279\n",
            "Early stopping at epoch 5\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6762, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.9042\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.6488\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.8396\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=1.8399\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6759, Val Loss=1.3083\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.6109\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6760, Val Loss=2.0128\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6758, Val Loss=1.1946\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6761, Val Loss=1.6955\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6760, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6759, Val Loss=1.7867\n",
            "Early stopping at epoch 8\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.8750\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6757, Val Loss=1.5598\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6757, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6758, Val Loss=1.7295\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6757, Val Loss=1.3295\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6757, Val Loss=1.5860\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6759, Val Loss=1.8391\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6760, Val Loss=1.4757\n",
            "Early stopping at epoch 8\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6761, Val Loss=1.9882\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6757, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.1940\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.8393\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.8440\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6760, Val Loss=1.6205\n",
            "Early stopping at epoch 6\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6762, Val Loss=1.8458\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6761, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.5596\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.6651\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6762, Val Loss=1.5051\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6759, Val Loss=2.0474\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6761, Val Loss=1.6184\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6758, Val Loss=1.2412\n",
            "0.25\n",
            "Epoch 9: Train Loss=1.6760, Val Loss=1.5894\n",
            "0.25\n",
            "Epoch 10: Train Loss=1.6758, Val Loss=1.7183\n",
            "0.25\n",
            "Epoch 11: Train Loss=1.6760, Val Loss=1.4511\n",
            "Early stopping at epoch 11\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6759, Val Loss=1.5890\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6762, Val Loss=1.6195\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.5821\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.5846\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.9060\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6761, Val Loss=1.8315\n",
            "Early stopping at epoch 6\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6758, Val Loss=1.4511\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.4752\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.4767\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6759, Val Loss=1.7862\n",
            "Early stopping at epoch 4\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6760, Val Loss=1.7620\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.8678\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6760, Val Loss=1.4774\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6761, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6760, Val Loss=1.7628\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6761, Val Loss=1.9485\n",
            "Early stopping at epoch 6\n",
            "0.25\n",
            "Epoch 1: Train Loss=1.6762, Val Loss=1.8451\n",
            "0.25\n",
            "Epoch 2: Train Loss=1.6760, Val Loss=1.8458\n",
            "0.25\n",
            "Epoch 3: Train Loss=1.6759, Val Loss=1.3589\n",
            "0.25\n",
            "Epoch 4: Train Loss=1.6762, Val Loss=1.5578\n",
            "0.25\n",
            "Epoch 5: Train Loss=1.6759, Val Loss=1.6189\n",
            "0.25\n",
            "Epoch 6: Train Loss=1.6757, Val Loss=1.3330\n",
            "0.25\n",
            "Epoch 7: Train Loss=1.6758, Val Loss=1.6689\n",
            "0.25\n",
            "Epoch 8: Train Loss=1.6757, Val Loss=1.5940\n",
            "0.25\n",
            "Epoch 9: Train Loss=1.6758, Val Loss=2.0134\n",
            "Early stopping at epoch 9\n",
            "Best Precision: 0.25\n",
            "Best Model: CovertypeClass(\n",
            "  (layer1): Linear(in_features=54, out_features=128, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (drop1): Dropout(p=0.2, inplace=False)\n",
            "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (act2): ReLU()\n",
            "  (drop2): Dropout(p=0.2, inplace=False)\n",
            "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (act3): ReLU()\n",
            "  (output): Linear(in_features=64, out_features=7, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Best learning rate: 0.001\n",
            "Best size of hidden layers: 64\n",
            "Best batch size: CovertypeClass(\n",
            "  (layer1): Linear(in_features=54, out_features=128, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (drop1): Dropout(p=0.2, inplace=False)\n",
            "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (act2): ReLU()\n",
            "  (drop2): Dropout(p=0.2, inplace=False)\n",
            "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (act3): ReLU()\n",
            "  (output): Linear(in_features=64, out_features=7, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}